{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Author: Ali Parandeh Presenting to: Credit Kudos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import statsmodels as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Construct dict of column names that need to be converted to category columns using dict comprehension\n",
    "dtypes= {col:dtype for col, dtype in zip(['', '', ''], ['category'] * 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Read data in, Use UCRN as index col and sort by index\n",
    "df = pd.read_csv('../data/data.csv', parse_dates=[2, 4, 8], infer_datetime_format=True, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# 2. Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Investigating transactions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Basic info about each dataset\n",
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def visualise_outliers(df: pd.DataFrame, figsize: Tuple[int, int]) -> None:\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i, col in enumerate(df.columns):\n",
    "        plt.subplot(len(df.columns), 1, i+1)\n",
    "        sns.boxplot(x=df[col])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "visualise_outliers(sales, (20, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def drop_outliers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Let's drop all the outliers (say anything above 3x standard deviations above mean)\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'int' or df[col].dtype == 'float':\n",
    "            mean, std = df[col].mean(), df[col].std()\n",
    "            cut_off  = mean + 3 * std\n",
    "            df = df[df[col] <= cut_off]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Investigating Schemes Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "tags": []
   },
   "source": [
    "### Feature Engineering using datetime columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Since datettime data don't work well with classification models, we need to feature engineer them to become categorical columns. One way to do this is to extract year, month and day of month or week from scheme start date. Schem start date can can be a working day or weekday or bank holiday. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def yearsago(years, from_date=None):\n",
    "    if from_date is None:\n",
    "        from_date = datetime.now()\n",
    "    return (from_date - relativedelta(years=years)).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "schemes['age'] = schemes.date_of_birth.apply(lambda x: yearsago(x.year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "schemes['start_date_year'] = df.start_date.dt.year\n",
    "schemes['start_date_month'] = df.start_date.dt.month\n",
    "schemes['start_date_week'] = df.start_date.dt.isocalendar().week\n",
    "schemes['start_date_day'] = schemes.start_date.dt.day\n",
    "schemes['start_date_day_of_week'] = schemes.start_date.dt.day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "schemes['first_scheme_start_year'] = schemes.first_scheme_start.dt.year\n",
    "schemes['first_scheme_start_month'] = schemes.first_scheme_start.dt.month\n",
    "schemes['first_scheme_start_week'] = schemes.first_scheme_start.dt.isocalendar().week\n",
    "schemes['first_scheme_start_day'] = schemes.first_scheme_start.dt.day\n",
    "schemes['first_scheme_start_day_of_week'] = schemes.first_scheme_start.dt.day_of_week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "tags": []
   },
   "source": [
    "## Merge Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Both tables must be joined before analysis can be carried out on the features vs label (scheme status). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Join both tables - Where there are not sales records, assume 0 sales.\n",
    "schemes_sales = schemes.join(sales).fillna({col: 0 for col in sales.columns})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "tags": []
   },
   "source": [
    "# 3. Explatory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = schemes_sales.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Slice columns into numerical, datetime,  categorical\n",
    "numerical_cols = list(df.select_dtypes('int').columns) + list(df.select_dtypes('float').columns)\n",
    "categorical_cols = df.select_dtypes('category').columns\n",
    "datetime_cols = df.select_dtypes('datetime').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#  Visualise numerical features vs income\n",
    "def visualise_numerical_correlations(df, no_cols, figsize):\n",
    "    numerical_cols = list(df.select_dtypes('int').columns) + list(df.select_dtypes('float').columns)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i, col in enumerate(numerical_cols):\n",
    "        try:\n",
    "            plt.subplot(int(np.ceil(len(numerical_cols) / 3)), 3, i+1)\n",
    "            plt.title(col)\n",
    "            # Use violin plots to understand data distribution better.\n",
    "            sns.violinplot(x=\"\", y=col, data=df, points='inner')\n",
    "        except Exception as e:\n",
    "            logging.error(e)\n",
    "        \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "visualise_numerical_correlations(df, 4, (20, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def visualise_categorical_correlations(df: pd.DataFrame, figsize: Tuple[int, int]) -> None:\n",
    "    # Construct list of categorical and boolean colunmns alongside the outcome label column \n",
    "    categorical_cols = ['', '']\n",
    "    \n",
    "    #  One-hot encode the categorical columns to enable pairwise correlations for the first 500 rows of data      \n",
    "    dummies = pd.get_dummies(df[categorical_cols])\n",
    "    corr = dummies.corr()\n",
    "\n",
    "    # Top half of the heatmap is redundant - Can use a mask to hide it         \n",
    "    mask = np.zeros_like(corr)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    with sns.axes_style(\"white\"):\n",
    "        f, ax = plt.subplots(figsize=figsize)\n",
    "        sns.heatmap(dummies.corr(),linewidths=.1,cmap=\"YlGnBu\", annot=True, mask=mask, vmax=.3, square=True)\n",
    "    plt.yticks(rotation=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "visualise_categorical_correlations(df, (30, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# 4. Build ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "label = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Let's see how balanced the label classes are in the dataset\n",
    "df[label].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Re-sampling techniques are divided in two categories:\n",
    "\n",
    "- Under-sampling the majority class(es).\n",
    "- Over-sampling the minority class.\n",
    "- Combining over- and under-sampling.\n",
    "- Create ensemble balanced sets.\n",
    "\n",
    "A third-party package to help with this is [imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn)\n",
    "\n",
    "For this task, we will not investigate this as data is fake (not fully representative of the actual real-world subscriptions data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop all rows with na data\n",
    "model_df = df.dropna().copy()\n",
    "\n",
    "label = 'status_end_of_q1'\n",
    "\n",
    "# One hot encode all categorical columns.\n",
    "# Drop all columns that have no correlations with the label\n",
    "X, y = pd.get_dummies(model_df.drop(columns=[label])).values, model_df[label].values\n",
    "\n",
    "# Split data 70%-30% into training set and test set,\n",
    "# As labels column (active and cancelled subscription) classes are unbalanced - we will use a stratified split to represent this unbalance in the test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0, stratify=y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print ('Training cases: %d\\nTest cases: %d' % (X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Set regularization rate\n",
    "reg = 0.01\n",
    "\n",
    "# train a logistic regression model on the training set\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print('Predicted labels: ', predictions)\n",
    "print('Actual labels:    ' ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn. metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The classification report includes the following metrics for each class (False and True) on the outcome column (label)\n",
    "\n",
    "- **Precision:** Of the predictions the model made for this class, what proportion were correct?\n",
    "- **Recall:** Out of all of the instances of this class in the test dataset, how many did the model identify?\n",
    "- **F1-Score:** An average metric that takes both precision and recall into account.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Counter(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(\"Overall Precision:\",precision_score(y_test, predictions, pos_label=\"Cancelled\"))\n",
    "print(\"Overall Recall:\",recall_score(y_test, predictions, pos_label=\"Cancelled\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_scores = model.predict_proba(X_test)\n",
    "print(y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1], pos_label=\"\")\n",
    "\n",
    "# plot ROC curve\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "# Plot the diagonal 50% line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# Plot the FPR and TPR achieved by our model\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The ROC chart shows the curve of the true and false positive rates for different threshold values between 0 and 1. A perfect classifier would have a curve that goes straight up the left side and straight across the top. The diagonal line across the chart represents the probability of predicting correctly with a 50/50 random prediction; so we obviously want the curve to be higher than that (or our model is no better than simply guessing!).\n",
    "\n",
    "The area under the curve (AUC) is a value between 0 and 1 that quantifies the overall performance of the model. The closer to 1 this value is, the better the model. scikit-Learn includes a function to calculate this metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "There are several ways we can improve this AUC and precision and recall scores:\n",
    "\n",
    "1. Scaling numeric features so they're on the same scale. This prevents features with large values from producing coefficients that disproportionately affect the predictions.\n",
    "2. Trying a different algorithm. Previously we used a logistic regression algorithm, which is a linear algorithm. There are many kinds of classification algorithm we could try, including:\n",
    "   - **Support Vector Machine algorithms:** Algorithms that define a hyperplane that separates classes.\n",
    "   - **Tree-based algorithms:** Algorithms that build a decision tree to reach a prediction\n",
    "   - **Ensemble algorithms:** Algorithms that combine the outputs of multiple base algorithms to improve generalizability.\n",
    "3. Hyperparameter Tuning on algorithms to build a model that fit the data better while avoiding underfitting and overfitting.\n",
    "4. Instead of dropping missing data, impute missing values with statistically sound values such that we have more data to train with.\n",
    "5. Feature engineering new features that correlate with the labels we want to predict on better.\n",
    "6. Principal Component Analysis (PCA) to reduce features / dimensions in the data that do not help in constructing an accurate model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# Tring a different algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# train a AdaBoostClassifier model on the training set\n",
    "model = AdaBoostClassifier(n_estimators=5).fit(X_train, y_train)\n",
    "\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "y_scores = model.predict_proba(X_test)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print ('Confusion Matrix:\\n',cm, '\\n')\n",
    "print('Accuracy:', accuracy_score(y_test, predictions))\n",
    "print(\"Overall Precision:\",precision_score(y_test, predictions, pos_label=\"\"))\n",
    "print(\"Overall Recall:\",recall_score(y_test, predictions, pos_label=\"\"))\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('\\nAUC: ' + str(auc))\n",
    "\n",
    "# calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1], pos_label='')\n",
    "\n",
    "# plot ROC curve\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "# Plot the diagonal 50% line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# Plot the FPR and TPR achieved by our model\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Saving and Loading model for inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model as a pickle file\n",
    "filename = '../models/income_model.pkl'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X_new = np.array([[0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print ('New sample: {}'.format(list(X_new[0])))\n",
    "\n",
    "# Get a prediction\n",
    "pred = model.predict(X_new)\n",
    "\n",
    "# The model returns an array of predictions - one for each set of features submitted\n",
    "# In our case, we only submitted one patient, so our prediction is the first one in the resulting array.\n",
    "print('Predicted outcome is {}'.format(pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print ('New sample: {}'.format(list(X_new[1])))\n",
    "pred = model.predict(X_new)\n",
    "print('Predicted outcome is {}'.format(pred[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "As shown above, given an array of values based on the defined columns, one can get a prediction from the model. The model has been trained on the patterns seen in the data. In particular, the relationships between each feature column and the label column. The model is in fact a function that has mapped a hyperplane in a high dimensional search space. \n",
    "\n",
    "[scikit-learn](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) has a great visual on how each algorithm can build a different model that create a different separation. In this notebook, we used logistic regression and AdaBoostClassifier algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img src='https://scikit-learn.org/stable/_images/sphx_glr_plot_classifier_comparison_001.png' />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
